---
- name: Gather some information on user & project
  hosts: openstack
  tasks:
    - name: Debug EE environment
      ansible.builtin.command: /usr/bin/env
      register: env_out
      tags: [ debug, never ]

    - name: Debug EE environment
      ansible.builtin.debug:
        msg: "Environment is {{env_out}}"
      tags: [ debug, never ]

    - name: Get openstack user name
      ansible.builtin.shell:
        cmd: openstack user show "$(openstack token issue -f value -c user_id)" -f value -c name
      register: openstack_cli_user

    - name: Debug openstack cli user
      ansible.builtin.debug:
        var: openstack_cli_user
      tags: [ debug, never ]

    - name: Set user name
      ansible.builtin.set_fact:
        appliance_user: "{{ openstack_cli_user.stdout | default( 'ipuuser') }}"

    - name: Get user's openstack project ID
      ansible.builtin.shell:
        cmd: openstack token issue -f value -c project_id
      register: openstack_cli_proj

    - name: Debug openstack cli proj ID
      ansible.builtin.debug:
        var: openstack_cli_proj
      tags: [ debug, never ]

    - name: Set user project ID fact
      ansible.builtin.set_fact:
        appliance_project: "{{ openstack_cli_proj.stdout | default( 'ipuops') }}"

    - name: Get tenancy name
      ansible.builtin.shell:
        cmd: openstack project show "$(openstack token issue -f value -c project_id)" -f value -c name
      register: openstack_cli_tenancy_name

    - name: Debug openstack tenancy name
      ansible.builtin.debug:
        msg: "{{ openstack_cli_tenancy_name.stdout }}"
      tags: [ debug, never ]

    - name: Set user tenancy name fact
      ansible.builtin.set_fact:
        appliance_tenancy: "{{ openstack_cli_tenancy_name.stdout | default( 'ipuops') }}"

    - name: Get the name of the cloud from the tags on our tenancy
      ansible.builtin.shell:
        cmd: openstack project show {{ appliance_tenancy }} -f json -c tags
      register: openstack_cloud_name

    - name: Debug openstack name
      ansible.builtin.debug:
        var: openstack_cloud_name
      tags: [ debug, never ]

    - name: Extract cloud name
      ansible.builtin.set_fact:
        gc_cloud: "{{ openstack_cloud_name.stdout | from_json | json_query('tags[0]') | replace('-','_') }}"

    - ansible.builtin.debug:
        msg: "CLOUD NAME is: {{ gc_cloud }}"
      tags: [ debug, never ]

    - name: Set allocation name
      ansible.builtin.set_fact:
        allocation_name: "{{appliance_user}}-{{cluster_name}}"

    - name: Generate partition name
      ansible.builtin.set_fact:
        user_partition: "{{ ('Single reconfigurable partition' in partition_choice) | ternary(allocation_name ~ '-reconfig', 'N/A')  }}"

    - name: Define the terraform state
      ansible.builtin.set_fact:
        terraform_state: "{{ cluster_state | default('present') }}"

    - name: Include the vars we need
      ansible.builtin.include_vars:
        file: "{{ item }}"
      loop:
        - "{{playbook_dir}}/group_vars/{{gc_cloud}}.yaml"
        - "{{playbook_dir}}/group_vars/ipums.yaml"


- name: Create the frontend (needs super powers) - runs only on create
  hosts: openstack
  tasks:
    - name: Include poplar infra role
      ansible.builtin.include_role:
        name: poplar_infra
        tasks_from: "present.yml"
      when: terraform_state == "present"


- name: Create/Destroy the Poplar VM - always runs
  hosts: openstack
  roles:
    - cluster_infra
  vars:
    image_name: "{{ poplar_appliance_images | selectattr('name', 'equalto', operating_system) | map(attribute='image_name') | first }}"
    image_tag: "{{ poplar_appliance_images | selectattr('name', 'equalto', operating_system) | map(attribute='image_tag') | first }}"

  post_tasks:
    - name: Wait for Monitoring to become available
      uri:
        url: "http://{{ zenith_fqdn_monitoring }}"
        method: GET
        follow_redirects: safe
      register: monitoring_uri
      changed_when: false
      failed_when: >-
        monitoring_uri.status < 0 or
        monitoring_uri.status == 404 or
        monitoring_uri.status >= 500
      retries: 60
      delay: 10
      # 404 and 503 are the statuses that are seen when the Zenith service is not ready yet
      # An SSL error is indicated as -1, which will occur while cert-manager fetches certificates
      until: monitoring_uri.status not in [404, 503, -1]
      when: (cluster_state | default('present')) == 'present'
      tags: never

    - name: Wait for webconsole to become available
      uri:
        url: "http://{{ zenith_fqdn_webconsole }}"
        method: GET
        follow_redirects: safe
      register: webconsole_uri
      changed_when: false
      failed_when: >-
        webconsole_uri.status < 0 or
        webconsole_uri.status == 404 or
        webconsole_uri.status >= 500
      retries: 60
      delay: 10
      # 404 and 503 are the statuses that are seen when the Zenith service is not ready yet
      # An SSL error is indicated as -1, which will occur while cert-manager fetches certificates
      until: webconsole_uri.status not in [404, 503, -1]
      when: (cluster_state | default('present')) == 'present'
      tags: never


- name: Destroy the frontend (needs super powers)
  hosts: openstack
  vars:
    allocation_name: "{{ allocation_name }}"
    appliance_user: "{{ appliance_user }}"
    appliance_project: "{{ appliance_project }}"
    appliance_tenancy: "{{ appliance_tenancy }}"
    terraform_state: "{{ terraform_state }}"
  tasks:
    - name: Include poplar infra role
      ansible.builtin.include_role:
        name: poplar_infra
        tasks_from: "absent.yml"
      when: terraform_state == "absent"


- hosts: localhost
  tasks:
    - name: debug inventory
      debug: var=hostvars

# Write the outputs as the final task
- hosts: localhost
  tasks:
    - debug: var=outputs
      vars:
        outputs:
          cluster_access_ip: "{{ hostvars[groups['openstack'][0]].cluster_access_ip }}"
          cluster_user: "{{ hostvars[groups['openstack'][0]].cluster_user }}"
          cluster_flavour_name: "{{ hostvars[groups['openstack'][0]].cluster_flavour_name }}"
          cluster_operating_system: "{{ hostvars[groups['openstack'][0]].operating_system }}"
          allocation_name: "{{ hostvars[groups['openstack'][0]].allocation_name }}"
          allocation_size: "{{ hostvars[groups['openstack'][0]].allocation_size }}"
          ipuof_vipu_api_partition_id: "{{ hostvars[groups['openstack'][0]].user_partition | default('none') }}"
          ipuof_vipu_api_host: "{{ hostvars[groups['openstack'][0]].vipu_servers[appliance_tenancy]['ctrl_net_ip'] }}"
